{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e71ce-6821-4a42-be90-1b01b5eacd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\**\\**\\深度学习验证\\merged_all.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "df.head()\n",
    "df.info()\n",
    "df[\"Level_OA\"].value_counts()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=2025)\n",
    "df[\"fold_id\"] = -1\n",
    "for fold, (_, val_idx) in enumerate(skf.split(df, df[\"Level_OA\"])):\n",
    "    df.loc[val_idx, \"fold_id\"] = fold\n",
    "\n",
    "df[\"fold_id\"].value_counts()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in\n",
    "                [\"Name\",\"Level_OA\",\"fold_id\",\"P_OA\"]] \n",
    "X = df[feature_cols].values\n",
    "y = df[\"Level_OA\"].values\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "model = LGBMClassifier(num_leaves=31, learning_rate=0.05,\n",
    "                       n_estimators=300, random_state=2025)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=2025)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring=\"f1_macro\")\n",
    "print(\"Macro-F1 (10-fold):\", scores.mean(), \"±\", scores.std())\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, X, y, cv=cv,\n",
    "                            scoring=[\"accuracy\", \"f1_macro\", \"roc_auc_ovr\"],\n",
    "                            return_train_score=False)\n",
    "\n",
    "print(\"Accuracy:\", cv_results[\"test_accuracy\"].mean())\n",
    "print(\"Macro-F1:\", cv_results[\"test_f1_macro\"].mean())\n",
    "print(\"AUC:\", cv_results[\"test_roc_auc_ovr\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff7dcf-30d8-46bf-bba9-b5e5ce3007b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.special import softmax   # ✅ 用 scipy 的 softmax\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "SEED = 2025\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "PATH = r\"C:\\**\\**\\深度学习验证\\merged_all.xlsx\"\n",
    "\n",
    "read_ok = False\n",
    "try:\n",
    "    df = pd.read_excel(PATH, engine=\"openpyxl\")\n",
    "    read_ok = True\n",
    "except Exception:\n",
    "    try:\n",
    "        import xlrd \n",
    "        df = pd.read_excel(PATH, engine=\"xlrd\")\n",
    "        read_ok = True\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "print(f\"数据行数: {len(df)}\")\n",
    "\n",
    "need_cols = [\"Name\",\"Level_OA\",\"G\",\"P_PI3K\",\"P_PPAR\",\"P_ROS\",\"P_LPS\"]\n",
    "for c in need_cols:\n",
    "    assert c in df.columns, f\"缺列：{c}\"\n",
    "df[\"Level_OA\"] = df[\"Level_OA\"].astype(int)\n",
    "\n",
    "if \"fold_id\" not in df.columns:\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "    fold_ids = np.zeros(len(df), dtype=int) - 1\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(df, df[\"Level_OA\"])):\n",
    "        fold_ids[val_idx] = fold\n",
    "    df[\"fold_id\"] = fold_ids\n",
    "print(\"fold 分布：\", df[\"fold_id\"].value_counts().to_dict())\n",
    "\n",
    "exclude_cols = {\"Name\",\"Level_OA\",\"fold_id\",\"G\",\"P_PI3K\",\"P_PPAR\",\"P_ROS\",\"P_LPS\",\"P_OA\"}\n",
    "X_cols = [c for c in df.columns if c not in exclude_cols and df[c].dtype != 'O']\n",
    "print(f\"结构描述符个数: {len(X_cols)}\")\n",
    "\n",
    "def feature_columns(mode):\n",
    "    if mode == \"X-only\":\n",
    "        return X_cols\n",
    "    elif mode == \"X+Y\":\n",
    "        return X_cols + [\"G\"]\n",
    "    elif mode == \"X+Z\":\n",
    "        return X_cols + [\"P_PI3K\",\"P_PPAR\",\"P_ROS\",\"P_LPS\"]\n",
    "    elif mode == \"X+Y+Z\":\n",
    "        return X_cols + [\"G\",\"P_PI3K\",\"P_PPAR\",\"P_ROS\",\"P_LPS\"]\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "# =========================\n",
    "# 1) 轻量 Transformer 模型\n",
    "# =========================\n",
    "class TinyTabTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, n_classes=3, d_model=64, n_heads=4, n_layers=2, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(in_dim, d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=d_model*2,\n",
    "            dropout=dropout, batch_first=True, activation=\"gelu\"\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model//2, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, in_dim) -> (B, 1, d_model)\n",
    "        x = self.proj(x).unsqueeze(1)\n",
    "        x = self.encoder(x)                 # (B, 1, d_model)\n",
    "        x = self.norm(x.squeeze(1))         # (B, d_model)\n",
    "        logits = self.head(x)               # (B, n_classes)\n",
    "        return logits\n",
    "\n",
    "def train_one_fold(train_X, train_y, val_X, val_y,\n",
    "                   epochs=500, batch_size=16, lr=1e-3, weight_decay=1e-4,\n",
    "                   d_model=64, n_heads=4, n_layers=2, dropout=0.35, patience=50):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_classes = len(np.unique(train_y))\n",
    "\n",
    "    model = TinyTabTransformer(in_dim=train_X.shape[1], n_classes=n_classes,\n",
    "                               d_model=d_model, n_heads=n_heads,\n",
    "                               n_layers=n_layers, dropout=dropout).to(device)\n",
    "\n",
    "    classes, counts = np.unique(train_y, return_counts=True)\n",
    "    weight_map = {c: (np.sum(counts)/cnt) for c,cnt in zip(classes, counts)}\n",
    "    weights = torch.tensor([weight_map[i+1] for i in range(n_classes)], dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_ds = TensorDataset(torch.tensor(train_X, dtype=torch.float32),\n",
    "                             torch.tensor(train_y-1, dtype=torch.long))\n",
    "    val_ds   = TensorDataset(torch.tensor(val_X, dtype=torch.float32),\n",
    "                             torch.tensor(val_y-1, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_f1, best_state, no_improve = -1.0, None, 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for bx, by in train_loader:\n",
    "            bx, by = bx.to(device), by.to(device)\n",
    "            logits = model(bx)\n",
    "            loss = criterion(logits, by)\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        all_pred, all_prob, all_true = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for bx, by in val_loader:\n",
    "                bx = bx.to(device)\n",
    "                logits = model(bx)\n",
    "                prob = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "                pred = prob.argmax(axis=1)\n",
    "                all_prob.append(prob); all_pred.append(pred); all_true.append(by.numpy())\n",
    "\n",
    "        y_true = np.concatenate(all_true)\n",
    "        y_pred = np.concatenate(all_pred)\n",
    "        y_prob = np.concatenate(all_prob)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict({k:v for k,v in best_state.items()})\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model(torch.tensor(val_X, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "        val_prob   = softmax(val_logits, axis=1)  \n",
    "        val_pred   = val_prob.argmax(axis=1)\n",
    "\n",
    "    y_true0 = (val_y-1)\n",
    "    acc = accuracy_score(y_true0, val_pred)\n",
    "    f1  = f1_score(y_true0, val_pred, average='macro')\n",
    "    try:\n",
    "        auc = roc_auc_score(label_binarize(y_true0, classes=[0,1,2]),\n",
    "                            val_prob, average='macro', multi_class='ovr')\n",
    "    except:\n",
    "        auc = np.nan\n",
    "    return acc, f1, auc\n",
    "\n",
    "# =========================\n",
    "# 2) 10-fold 训练\n",
    "# =========================\n",
    "modes = [\"X-only\",\"X+Y\",\"X+Z\",\"X+Y+Z\"]\n",
    "results = {}\n",
    "\n",
    "for mode in modes:\n",
    "    cols = feature_columns(mode)\n",
    "    print(f\"\\n=== 模式: {mode} | 特征数: {len(cols)} ===\")\n",
    "    acc_list, f1_list, auc_list = [], [], []\n",
    "\n",
    "    for fold in range(10):\n",
    "        train_idx = df[\"fold_id\"] != fold\n",
    "        val_idx   = df[\"fold_id\"] == fold\n",
    "\n",
    "        X_train = df.loc[train_idx, cols].values\n",
    "        y_train = df.loc[train_idx, \"Level_OA\"].astype(int).values\n",
    "        X_val   = df.loc[val_idx,   cols].values\n",
    "        y_val   = df.loc[val_idx,   \"Level_OA\"].astype(int).values\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val   = scaler.transform(X_val)\n",
    "\n",
    "        acc, f1, auc = train_one_fold(X_train, y_train, X_val, y_val)\n",
    "        acc_list.append(acc); f1_list.append(f1); auc_list.append(auc)\n",
    "\n",
    "    results[mode] = {\n",
    "        \"acc_mean\": np.mean(acc_list), \"acc_std\": np.std(acc_list),\n",
    "        \"f1_mean\":  np.mean(f1_list),  \"f1_std\":  np.std(f1_list),\n",
    "        \"auc_mean\": np.nanmean(auc_list), \"auc_std\": np.nanstd(auc_list),\n",
    "    }\n",
    "    print(f\"[{mode}] 10-fold 结果：Acc={np.mean(acc_list):.3f}±{np.std(acc_list):.3f} | \"\n",
    "          f\"F1={np.mean(f1_list):.3f}±{np.std(f1_list):.3f} | \"\n",
    "          f\"AUC={np.nanmean(auc_list):.3f}±{np.nanstd(auc_list):.3f}\")\n",
    "\n",
    "pd.DataFrame(results).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05310872-aee9-4217-a8d7-e211f07bc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df.loc[:, feature_columns(\"X+Y+Z\")].values\n",
    "y_all = df[\"Level_OA\"].astype(int).values\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    LGBMClassifier(random_state=2025, class_weight=\"balanced\"),\n",
    "    param_distributions=param_dist, n_iter=100,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=2025),\n",
    "    n_jobs=-1, random_state=2025\n",
    ")\n",
    "rs.fit(X_all, y_all)\n",
    "print(rs.best_params_, rs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773711eb-de5a-4b8a-a608-f4832eb1a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "PATH_IN  = r\"C:\\**\\**\\大样本预测\\7565.xlsx\"\n",
    "PATH_OUT = r\"C:\\**\\**\\大样本预测\\7565_filled.xlsx\"\n",
    "\n",
    "df = pd.read_excel(PATH_IN)\n",
    "\n",
    "num_cols = [c for c in df.columns if np.issubdtype(df[c].dtype, np.number)]\n",
    "\n",
    "df[num_cols] = df[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "\n",
    "os.makedirs(os.path.dirname(PATH_OUT), exist_ok=True)\n",
    "df.to_excel(PATH_OUT, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50769a07-9a4b-4fd2-8c56-28e1249c7611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
